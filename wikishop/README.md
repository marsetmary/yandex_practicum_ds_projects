# Классификация токсичных комментариев в интернет-магазине «Викишоп»

**Цель проекта:** обучить модель для автоматического выявления токсичных комментариев пользователей, чтобы направлять их на модерацию.

---

## Задачи проекта
- Загрузка, предобработка и исследование данных  
- Подготовка признаков и обучение моделей  
- Использование BERT и выбор лучшей модели

---

## Основные результаты
- Данные: 159 292 комментария на английском языке, пропусков и дубликатов нет, дисбаланс классов присутствует  
- Признаки: токенизация и лемматизация через spaCy, векторизация TF-IDF и Word2Vec  
- Классические модели: Logistic Regression, Random Forest, SGDClassifier  
  - **Лучший результат среди классических моделей:** Logistic Regression на TF-IDF, F1 = 0.750  
- Модель с BERT: предобученная модель HuggingFace BERT Toxic Comment Classification + небольшая нейросеть с одним скрытым слоем, функция потерь — кросс-энтропия  
  - **Результат на тесте:** F1 = 0.885, стабильнее и лучше классических моделей

---

## Выводы
- Лучшая модель — небольшая нейронная сеть на признаках BERT Toxic Comment Classification  
- Модель обеспечивает более высокую метрику F1 по сравнению с классическими моделями на TF-IDF и Word2Vec  
- Решение может быть интегрировано в сервис «Викишоп» для автоматической модерации комментариев

---
## Используемые библиотеки
pandas, numpy, matplotlib, seaborn, sklearn, torch, transformers, spacy, nltk, gensim, pytorch_lightning, wordcloud, torchmetrics
